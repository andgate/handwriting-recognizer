{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1410eba6",
   "metadata": {},
   "source": [
    "This notebook is used to for to train and build the model that our webapp will ultimately serve to users."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12906043",
   "metadata": {},
   "source": [
    "Import required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import TensorDataset\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import functional\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "import gradio as gr\n",
    "import onnx\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b305f06",
   "metadata": {},
   "source": [
    "Define neural network architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcd6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DigitClassifier, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # Input size (1, 28, 28)\n",
    "            # Convolutional Base\n",
    "            # First convolution block\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), # (32, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (32, 14, 14)\n",
    "            # Second convolutional block\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2), # (64, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),  # (64, 7, 7)\n",
    "\n",
    "            # Linear head\n",
    "            nn.Flatten(),\n",
    "            # First linear block\n",
    "            nn.Linear(64*7*7, 128),\n",
    "            nn.ReLU(),\n",
    "            # Second linear block\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c50f0522",
   "metadata": {},
   "source": [
    "Setup pytorch lightning module for training the digit classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9690c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitDigitClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super(LitDigitClassifier, self).__init__()\n",
    "        self.model = DigitClassifier()\n",
    "        self.loss = nn.NLLLoss()\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.epoch_train_accs = []\n",
    "        self.epoch_test_accs = []\n",
    "        self.train_acc = torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "        self.test_acc =  torchmetrics.Accuracy(task='multiclass', num_classes=10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def on_fit_start(self):\n",
    "        pl.seed_everything(42, workers=True) \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_pred = self.model(X)\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        self.train_losses.append(loss.item())\n",
    "        self.epoch_train_accs.append(self.train_acc(y_pred, y).item())\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X, y = batch\n",
    "        y_pred = self.model(X)\n",
    "        loss = self.loss(y_pred, y)\n",
    "\n",
    "        self.test_losses.append(loss.item())\n",
    "        self.epoch_test_accs.append(self.test_acc(y_pred, y).item())\n",
    "\n",
    "        self.log('val_loss', loss, logger=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.model.parameters(), lr=1e-4)\n",
    "        return optimizer\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        avg_train_loss = np.mean(self.train_losses)\n",
    "        self.train_losses.clear()\n",
    "        \n",
    "        avg_train_acc = np.mean(self.epoch_train_accs)\n",
    "        self.epoch_train_accs.clear()\n",
    "        self.train_acc.reset()\n",
    "\n",
    "        avg_test_loss = np.mean(self.test_losses)\n",
    "        self.test_losses.clear()\n",
    "        \n",
    "        avg_test_acc = np.mean(self.epoch_test_accs)\n",
    "        self.epoch_test_accs.clear()\n",
    "        self.test_acc.reset()\n",
    "\n",
    "        \n",
    "        self.logger.experiment.add_scalars('loss', { 'train': avg_train_loss, 'test': avg_test_loss }, self.current_epoch)\n",
    "        self.logger.experiment.add_scalars('accuracy', { 'train': avg_train_acc, 'test': avg_test_acc }, self.current_epoch)\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        avg_loss = np.mean(self.test_losses)\n",
    "        self.test_losses.clear()\n",
    "        \n",
    "        avg_acc = np.mean(self.epoch_test_accs)\n",
    "        self.epoch_test_accs.clear()\n",
    "        self.test_acc.reset()\n",
    "\n",
    "        self.logger.experiment.add_scalars('loss', { 'test': avg_loss }, self.current_epoch)\n",
    "        self.logger.experiment.add_scalars('accuracy', { 'test': avg_acc }, self.current_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44549fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a new instance of your model architecture\n",
    "# model = LitDigitClassifier()\n",
    "\n",
    "# try:\n",
    "#     # Load the state_dict from the file\n",
    "#     model.model.load_state_dict(torch.load('model_weights.pth'))\n",
    "# except:\n",
    "#     print('Unable to load previous model')\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dcfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertImage(object):\n",
    "    def __call__(self, x):\n",
    "        return 1 - x\n",
    "    \n",
    "class CorruptedMNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset):\n",
    "        self.base_dataset = base_dataset\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image, label = self.base_dataset[index]\n",
    "        return image, label.item()  # Convert label tensor to int\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "def tf_to_torch(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for example in tfds.as_numpy(dataset):\n",
    "        image, label = example['image'], example['label']\n",
    "        image = image.astype(np.float32) / 255\n",
    "        image = torch.from_numpy(image).permute((2, 0, 1))\n",
    "        image = functional.normalize(image, (0.1307, ), (0.3081, ))\n",
    "        images.append(image)\n",
    "        labels.append(torch.tensor(label))\n",
    "    return TensorDataset(torch.stack(images), torch.stack(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "429236ba",
   "metadata": {},
   "source": [
    "Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ad413",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_dataset_paths = [\n",
    "    'shot_noise',\n",
    "    'impulse_noise',\n",
    "    'glass_blur',\n",
    "    'motion_blur',\n",
    "    'shear',\n",
    "    'scale',\n",
    "    'rotate',\n",
    "    'brightness',\n",
    "    'translate',\n",
    "    'stripe',\n",
    "    'fog',\n",
    "    'spatter',\n",
    "    'dotted_line',\n",
    "    'zigzag',\n",
    "    'canny_edges'\n",
    "]\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "inv_minst_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    InvertImage(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "spatial_mnist_transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(degrees=15), # rotation can cause some weird issues\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.9, 1.1)),\n",
    "    mnist_transform\n",
    "])\n",
    "\n",
    "inv_spatial_mnist_transform = transforms.Compose([\n",
    "    # transforms.RandomRotation(degrees=15), # rotation can cause some weird issues\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.2, 0.2), scale=(0.9, 1.1)),\n",
    "    inv_minst_transform\n",
    "])\n",
    "\n",
    "original_train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=mnist_transform\n",
    ")\n",
    "inv_train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=inv_minst_transform\n",
    ")\n",
    "spatial_train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=spatial_mnist_transform\n",
    ")\n",
    "inv_spatial_train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=inv_spatial_mnist_transform\n",
    ")\n",
    "corrupted_mnist_train_dataset = ConcatDataset(map(lambda x: \n",
    "    CorruptedMNISTDataset(tf_to_torch(tfds.load(f'mnist_corrupted/{x}', split='train', shuffle_files=False, download=True, data_dir='./data', with_info=False))),\n",
    "    corrupted_dataset_paths\n",
    "))\n",
    "train_dataset = ConcatDataset([original_train_dataset, inv_train_dataset, spatial_train_dataset, inv_spatial_train_dataset, corrupted_mnist_train_dataset])\n",
    "\n",
    "original_test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=mnist_transform\n",
    ")\n",
    "\n",
    "inv_test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=inv_minst_transform\n",
    ")\n",
    "\n",
    "corrupted_mnist_test_dataset = ConcatDataset(map(lambda x: \n",
    "    CorruptedMNISTDataset(tf_to_torch(tfds.load(f'mnist_corrupted/{x}', split='test', shuffle_files=False, download=True, data_dir='./data', with_info=False))),\n",
    "    corrupted_dataset_paths\n",
    "))\n",
    "\n",
    "test_dataset = ConcatDataset([original_test_dataset, inv_test_dataset, corrupted_mnist_test_dataset])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be1e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count occurrences of each class\n",
    "class_counts = np.zeros(10)\n",
    "for _, label in train_dataset:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Create a bar graph\n",
    "class_labels = np.arange(10)\n",
    "plt.bar(class_labels, class_counts)\n",
    "\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of Each Class in the Training Dataset')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Count occurrences of each class\n",
    "class_counts = np.zeros(10)\n",
    "for _, label in test_dataset:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Create a bar graph\n",
    "class_labels = np.arange(10)\n",
    "plt.bar(class_labels, class_counts)\n",
    "\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Counts of Each Class in the Test Dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "34809c6e",
   "metadata": {},
   "source": [
    "Preview some of the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54512b26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to unnormalize and convert tensor to a PIL image\n",
    "def unnormalize(tensor):\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    img = tensor.clone().detach().numpy()\n",
    "    img = (img * std) + mean\n",
    "    img = img.squeeze()\n",
    "    return img\n",
    "\n",
    "def preview_dataset(dataset):\n",
    "    _, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        idx = torch.randint(0, len(dataset), (1,)).item()\n",
    "        img, label = dataset[idx]\n",
    "        img_unnorm = unnormalize(img)\n",
    "        ax.imshow(img_unnorm, cmap='gray')\n",
    "        ax.set_title(f'Label: {label}')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "preview_dataset(corrupted_mnist_test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d44496fd",
   "metadata": {},
   "source": [
    "Train and test the model, then plot the train and test losses per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023a1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitDigitClassifier()\n",
    "logger = TensorBoardLogger('lightning_logs', name='mnist')\n",
    "early_stop_callback = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=True)\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=200,\n",
    "    min_epochs=3,\n",
    "    precision='32',\n",
    "    devices=torch.cuda.device_count(),\n",
    "    accelerator=\"gpu\",\n",
    "    logger=logger,\n",
    "    callbacks=[early_stop_callback]\n",
    ")\n",
    "trainer.fit(model, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce1a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34bfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of your model architecture\n",
    "digitClassifier = DigitClassifier()\n",
    "\n",
    "# Load the state_dict from the file\n",
    "digitClassifier.load_state_dict(torch.load('model_weights.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "digitClassifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be62bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to unnormalize and convert tensor to a PIL image\n",
    "def unnormalize(tensor):\n",
    "    mean = 0.1307\n",
    "    std = 0.3081\n",
    "    img = tensor.clone().detach().numpy()\n",
    "    img = (img * std) + mean\n",
    "    img = img.squeeze()\n",
    "    return img\n",
    "\n",
    "# Display a grid of sample images\n",
    "num_samples = 9\n",
    "fig, axes = plt.subplots(3, 3, figsize=(6, 6))\n",
    "\n",
    "digitClassifier.eval()\n",
    "for i, ax in enumerate(axes.ravel()):\n",
    "    idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "    img, label = train_dataset[idx]\n",
    "    img_unnorm = unnormalize(img)\n",
    "    with torch.no_grad():\n",
    "        prediction = torch.exp(digitClassifier(img.unsqueeze(0)))\n",
    "        predicted_label = torch.argmax(prediction, dim=1).item()\n",
    "    ax.imshow(img_unnorm, cmap='gray')\n",
    "    ax.set_title(f'Actual: {label}, Predicted: {predicted_label}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ee672b9",
   "metadata": {},
   "source": [
    "Experiment with gradio interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee98e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(image):\n",
    "    if image is None:\n",
    "        return {str(i): 0 for i in range(10)}\n",
    "    \n",
    "    digitClassifier.eval()\n",
    "    with torch.no_grad():\n",
    "        X = transforms.ToTensor()(image).unsqueeze(0)\n",
    "        y = torch.exp(digitClassifier(X)).tolist()[0]\n",
    "        confidences = {str(i): y[i] for i in range(10)}\n",
    "    return confidences\n",
    "    \n",
    "sketchpad = gr.Sketchpad(shape=(28, 28), invert_colors=False)\n",
    "label = gr.components.Label(num_top_classes=3)\n",
    "interface = gr.Interface(classify, sketchpad, label, live=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f13488e",
   "metadata": {},
   "source": [
    "Finally, export our trained model via ONNX to our webapps `asset` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf688ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 1, 28, 28)\n",
    "digitClassifier.eval()\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(\n",
    "    digitClassifier,                        # model being run\n",
    "    # model input (or a tuple for multiple inputs)\n",
    "    dummy_input,\n",
    "    # where to save the model (can be a file or file-like object)\n",
    "    \"src/assets/mnist.onnx\",\n",
    "    input_names = ['input'],     # the model's input names\n",
    "    output_names = ['output'],    # the model's output names\n",
    "    dynamic_axes = {\n",
    "        # variable length axes\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    },\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4999037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ONNX model\n",
    "onnx_model = onnx.load(\"src/assets/mnist.onnx\")\n",
    "\n",
    "# Check that the model is well formed\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "# Print a human readable representation of the graph\n",
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
